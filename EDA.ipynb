{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Scope of this project\n",
    "Get familiar with the _King County Housing Data_ and perform an **Exploratory Data Analysis** (EDA) with focus on the following particular requests by the stakeholder.\n",
    "\n",
    "The stakeholder: <br>\n",
    "Nicole Johnson, buyer, who seeks for a \"Lively, central neighborhood, middle price range, right timing (within a year)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "# Table of Content\n",
    "1) Import and first impression of the dataset\n",
    "2) Initial Hypotheses about the Dataset\n",
    "3) Explore and clean the dataset\n",
    "    - Add/remove columns\n",
    "    - Filtering\n",
    "    - Testing the hypotheses\n",
    "4) Recommendations for the stakeholder\n",
    "-------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import and first impression of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will load the data into the workspace as a _dataframe object_ using **_pandas_** and display the main characteristics of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries we need for your analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('data/King_County_House_prices_dataset.csv', parse_dates=['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, what size does the dataset has?\n",
    "print(\"\\n\", f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns.\", \"\\n\")\n",
    "\n",
    "# Now, let us take a view to the columns and their type:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For most of the columns the dtype looks reasonable except for _sqft_basement_ which is of type \"object\", but we expect it to be a \"float\" since the variable gives us the size of the basement in square feet.\n",
    "- For _waterfront_ we see that it is a \"float64\" and not boolean as we might have thought (either the house has a waterfront or not). So, lets have a quick view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.waterfront.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, rather than TRUE/FALSE the column has already been one-hot encoded and contains 0/1 as well as nan (not a number).<br>\n",
    "Speaking of nan, how many nan do we have in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for _waterfront_, _yr_renovated_ and _view_ the variables (i.e. columns) are complete in the sense that no missing values appear.<br>\n",
    "But, additionally let us check wether there are any duplications or multiple entries which need to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the _id_ which is unique for each house has 177 duplications. So, are there really duplications of complete rows or does the house id just occur more than once? (For example indicating that a house has been bought and sold several times within the given time period) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is not a single TRUE value, there are no duplications of complete rows. So, for now we will keep them. <br>\n",
    "Lastly, we will take a brief view on some basic descriptive statistical parameters for each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, allthough being numeric, statistics for variables such as _id_, _waterfront_, _zipcode_, _latitude_ and _longitude_ can be ignored.  \n",
    "To get more insights, let's visualise some variables of the table which might be of special interest for our purpose (i.e. the requests of the stakeholder):\n",
    "- the _price_\n",
    "- the _year built_ (and _year renovated_ if applicable)\n",
    "- the _living size_ and overall _(lot) size_ of the houses\n",
    "- quality - specified via _condition_ and _grade_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 7, figsize=(18, 8))\n",
    "\n",
    "sns.boxplot(ax=axes[0], data=df.price)\n",
    "sns.boxplot(ax=axes[1], data=df.yr_built)\n",
    "sns.boxplot(ax=axes[2], data=df['yr_renovated'])\n",
    "sns.boxplot(ax=axes[3], data=df['sqft_living'])\n",
    "sns.boxplot(ax=axes[4], data=df['sqft_lot'])\n",
    "sns.boxplot(ax=axes[5], data=df['condition'])\n",
    "sns.boxplot(ax=axes[6], data=df['grade'])\n",
    "\n",
    "axes[0].set_title('Price [USD]')\n",
    "axes[1].set_title('Year Built')\n",
    "axes[2].set_title('Year Renovated')\n",
    "axes[3].set_title('size living [sqft]')\n",
    "axes[4].set_title('size lot [sqft]')\n",
    "axes[5].set_title('condition')\n",
    "axes[6].set_title('grade');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First insights regarding the overall data:** <br>\n",
    "- we can see that variables _price_, _sqft_living_ and _sqft_lot_ appear to be right skewed distributed as these have a couple of outliers towards higher values \n",
    "- _yr_built_ and _condition_ seem to have a rather symmetrical distribution\n",
    "- for most of the houses, the _grade_ varies between 6 and 9 with a few outliers towards both sides of the distribution \n",
    "- the variable _yr_renovated_ seems to be corrupted. So lets have a look at the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.yr_renovated.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are both nan and zeros which we need to have in mind when proceeding with the data cleaning. We already know that there are 3842 nan, so let's count the zeros, as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['yr_renovated'] == 0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, out of 21,597 values we have 3,842 nan plus 17,011 zeros, ergo - at maximum - 744 values left considering there may still be some duplications.<br>\n",
    "Note that the zeros can likely be interpreted as \"no\", so these houses have not been renovated at all:\n",
    "- houses renovated (ca. 744)\n",
    "- houses not renovated (ca. 17,011)\n",
    "- no statement (ca. 3,842)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First insight regarding a (possible) geographical pattern:** <br>\n",
    "Last, lets have a look if the year a house was built relates to a certain area, e.g. different development areas for different decades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='long', y='lat', hue='yr_built'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the western concentration of the population and a lot of newer houses (built in 2000) close to the coastline, especially in the north. Besides that, in the very west there seems to be an island with mainly older houses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Initial Hypotheses about the Dataset\n",
    "\n",
    "Hypotheses related to the stakeholder: <br>\n",
    "To buy a central neighborhood house in middle price range with right timing (within a year) it will\n",
    "- H1) be older than 50 years and has not been renovated in the last 25 years or\n",
    "- H2) has a below-average grade or\n",
    "- H3) has a below-average livingsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Explore and clean the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with the cleaning of the data, it is suitable to specify and define the stakeholders requests in terms of available parameters:<br>\n",
    "a) lively, central neighborhood\n",
    "b) middle price range\n",
    "c) right timing (within a year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) lively, central neighborhood <br>\n",
    "The term \"lively\" is a bit vague and can be interpreted differently. So for a non-local it cannot be linked without domain knowledge to certain longitudes/latitudes or zip codes. The term \"central neighborhood\" on the other hand can be addressed directly to a - yet to be defined - subset of zip codes. One may either define \"central\" in geographic terms or \"central neighborhood\" in terms of an area with higher population density.<br>\n",
    "\n",
    "- b) middle price range <br>\n",
    "This is a rather concrete condition. But instead of using the price itself, we will address it by normalizing the price by estimating the price per squarefeet. Furthermore, we define \"middle price range\" by choosing the 40% to 60% percentiles.\n",
    "\n",
    "- c) right timing (within a year) <br>\n",
    "So, our stakeholder wants to time the equity market. For that purpose, we will generate a new variable called \"month\" to analyze if there is a month showing significant lower house prices than other months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add/remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a copy of the original dataset and will adopt that one for our aims.\n",
    "df2 = df.copy()\n",
    "\n",
    "# As we want to know the right timing of buying within a year, we generate a 'month' column\n",
    "df2['month'] = df2.date.dt.month\n",
    "\n",
    "# Add prices for lot and living as prices per squarefeet\n",
    "df2['price_lot_per_sqft'] =  df2['price'] / df2['sqft_lot']\n",
    "df2['price_living_per_sqft'] =  df2['price'] / df2['sqft_living']\n",
    "\n",
    "# For our purpose, we don't need sqft_above and sqft_basement, as these add up to sqft_living and we are only interested \n",
    "# in the overall size of the living area and overall lot size.\n",
    "df2.drop(['sqft_above','sqft_basement'], axis=1, inplace=True)\n",
    "\n",
    "# As the stakeholder set no further conditions relating to the interior of the house, we will skip variables such as \"waterfront\", \n",
    "# number of floors, bathrooms, bedrooms etc.\n",
    "df2.drop(['bedrooms','bathrooms','floors','waterfront','view'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Living central in King County basically means living in Seattle. Therefore, we seek to select all zip codes in that county that belong to the city of Seattle. Luckily, we can find [here](https://www.usmapguide.com/washington/seattle-zip-code-map/) a list which we will use.  [This map](https://statisticalatlas.com/county/Washington/King-County/Population) showing the distribution of population density in King County supports the argument to use Seattle zip codes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip codes in Seattle\n",
    "zc_seattle = [98101 ,98102 ,98103 ,98104 ,98105 ,98106 ,98107 ,98108 ,98109 ,98110 ,98111 ,98112 ,98114 ,98115 ,98116 ,98117 ,98118 ,98119 ,98121 ,98122 ,98124 ,98125 ,98126 ,98129 ,98131 ,98132 ,98133 ,98134 ,98136 ,98138 ,98144 ,98145 ,98146 ,98148 ,98151 ,98154 ,98155 ,98158 ,98160 ,98161 ,98164 ,98166 ,98168 ,98170 ,98171 ,98174 ,98177 ,98178 ,98181 ,98184 ,98185 ,98188 ,98190 ,98191 ,98195 ,98198 ,98199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only houses in Seattle\n",
    "df2 = df2[df2['zipcode'].isin(zc_seattle)]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 8,973 buy/sell transactions to work with. Counting the transactions where we don't know if the house has been renovated or not yields 1,646. Let us remove them, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H1) be older than 50 years and has not been renovated in the last 25 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating the \"middle price range\" for prices living per squarefeet\n",
    "living40,living60 = df2.price_living_per_sqft.quantile([0.40, 0.60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the first hypothesis, we plot the histogram for the living price per square feet and estimate the age of the houses within our price range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df2, x=\"price_living_per_sqft\")\n",
    "plt.plot([living40, living40], [0, 420], color='r')\n",
    "plt.plot([living60, living60], [0, 420], color='r')\n",
    "plt.title('Histogram of price per sqft for living area' + '\\n' + '(red lines indicate 40 to 60 percentile range)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a mask to select only mid-price range\n",
    "mask1 = (living40 <= df2['price_living_per_sqft']) & (df2['price_living_per_sqft'] <= living60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot age of houses for selected price range\n",
    "sns.histplot(data=df2[mask1], x=\"yr_built\", bins=30)\n",
    "plt.plot([1972, 1972], [0, 140], color='r')\n",
    "plt.title('Histogram of the house age for mid-price segment'+ '\\n' + '(houses right of red line are younger than 50 years old)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that there are houses younger than 50 years. So, at his point we can already say that **hypothesis H1 is wrong**. <br>\n",
    "But still, let us have a look if the houses older than 50 years have all been renovated or not in the last 25 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a mask to select only mid-price range older than 50 years\n",
    "mask2 = (living40 <= df2['price_living_per_sqft']) & (df2['price_living_per_sqft'] <= living60) & (df2['yr_built']<=1972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of the renovation year for mid-priced houses older than 50 year\n",
    "sns.histplot(data=df2[mask2], x=\"yr_renovated\", bins=30)\n",
    "plt.title('Histogram of the renovation year of houses for mid-price segment'+ '\\n' + 'and being older than 50 years');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the vast majority at 0 show that most of the old houses have not been renovated at all, but let's zoom into the last decades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a mask to select only mid-price range older than 50 years & have been renovated\n",
    "mask3 = (living40 <= df2['price_living_per_sqft']) & (df2['price_living_per_sqft'] <= living60) & (df2['yr_built']<=1972) & (df2['yr_renovated']>1)\n",
    "\n",
    "# plot histogram of the renovation year for mid-priced houses older than 50 year\n",
    "sns.histplot(data=df2[mask3], x=\"yr_renovated\", bins=30)\n",
    "plt.plot([1997, 1997], [0, 17], color='r')\n",
    "plt.title('Histogram of the renovation year of old houses for mid-price segment'+ '\\n' + '(red line indicates 25 years renovation threshold)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even if we had only houses older than 50 years fitting to the conditions of the stakeholder (which is not the case), there are houses that have been renovated within the last 25 years, hence, **hypothesis H1 is wrong**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H2) has a below-average grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's visualise the grade distributions and calculate the overall mean grade for houses in Seattle, i.e. the center. Its a measure based on the King County grading system (between 1 - 13) and we will compare it with the data having constrains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df2['grade'], name='center grade'))\n",
    "fig.add_trace(go.Histogram(x=df2[mask1].grade, name='center grade with mid-price constrains'))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Histograms of the grade distributions', \n",
    "    xaxis_title_text='grade', \n",
    "    yaxis_title_text='count') \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['grade'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[mask1].grade.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers show that the grade for the houses does slightly increase using the stakeholders constrains compared to the overall grade. Therefore, **hypothesis H2 has been proven wrong**, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H3) has a below-average livingsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to hypothesis 2, we will calculate the average livingsquare for the center and compare it with the average livingsquare only in the 40% to 60% percentile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=df2['sqft_living'], name='center living size in sqft'))\n",
    "fig.add_trace(go.Histogram(x=df2[mask1].sqft_living, name='center living size in sqft with mid-price constrains'))\n",
    "\n",
    "# Overlay both histograms\n",
    "fig.update_layout(barmode='overlay')\n",
    "# Reduce opacity to see both histograms\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Histograms of the living sizes in sqft distributions', \n",
    "    xaxis_title_text='living size in sqft', \n",
    "    yaxis_title_text='count') \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sqft_living'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[mask1].sqft_living.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the average slightly increases. So, the average size of the living area inside the house is a tiny bit higher applying the mid-range price constrain. Therefore, **hypothesis H3 has also been proven wrong**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three hypotheses that have been stated in the beginning have been proven to be wrong. Although these were not very provocative and seemed to be \"no brainer\", the examinations show an unexpected result emphasizing the need to look into the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the best time for buying a house, we will group the transactions in the center in the mid-price range by month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[mask1].groupby(['month']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "fig.suptitle('Median prices for living and lot per sqft over the year', fontsize=24)\n",
    "sns.lineplot(ax=axes[0], data=df3[\"price_living_per_sqft\"])\n",
    "sns.lineplot(ax=axes[1], data=df3[\"price_lot_per_sqft\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we provide two possible answers for our stakeholder. Do we want to maximize the living area, the best choice is probably to buy in october. Do we concern about a big lot spring seems to be the right time - so in march or april."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Recommendations for the stakeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the stakeholders constrains, we might suggest:\n",
    "- an overall reasonable price in the mid-price segment for living area per squarefeet is between 263 USD and 321 USD\n",
    "- avoid buying in january and june and look for houses in october for maximizing living area\n",
    "- to maximize lot size, buy in march or april\n",
    "- the living area should have a size of about 1,800 squarefeet\n",
    "- the grade should at least be 7\n",
    "- most houses have been built 1940 - 1960 and 2000 - 2015. So when age is a criterium, looking for houses in these built phases enhances the supply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7345247fed2b526dcf29d28b4d1570fa30fc7af5fa11ab0a5bb651b37a635ea3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
